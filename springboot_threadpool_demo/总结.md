# 1. ThreadPoolExecutor数据成员

```
Private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING,0));
```

ctl主要用于存储线程池的工作状态以及池中正在运行的线程数。显然要在一个整型变量存储两个数据，只能将其一分为二。其中高3bit用于存储线程池的状态，低位的29bit用于存储正在运行的线程数。

   线程池具有以下五种状态，当创建一个线程池时初始化状态为RUNNING

| RUNNING    | 允许提交并处理任务                                           |
| ---------- | ------------------------------------------------------------ |
| SHUTDOWN   | 不允许提交新的任务，但是会处理完已提交的任务                 |
| STOP       | 不允许提交新的任务，也不会处理阻塞队列中未执行的任务，并设置正在执行的线程的中断标志位 |
| TIDYING    | 所有任务执行完毕，池中工作的线程数为0，等待执行terminated()勾子方法 |
| TERMINATED | terminated()勾子方法执行完毕                                 |

   注意，这里说的是线程池的状态而不是池中线程的状态。

   调用线程池的shutdown方法，将线程池由RUNNING（运行状态）转换为SHUTDOWN状态。

   调用线程池的shutdownNow方法，将线程池由RUNNING或SHUTDOWN状态转换为STOP状态。

   SHUTDOWN状态和STOP状态先会转变为TIDYING状态，最终都会变为TERMINATED





```
// Packing and unpacking ctl
private static int runStateOf(int c)     { return c & ~CAPACITY; }
private static int workerCountOf(int c)  { return c & CAPACITY; }
private static int ctlOf(int rs, int wc) { return rs | wc; }
```

ThreadPoolExecutor同时提供上述三个方法用于池中的线程查看线程池的状态和计算正在运行的线程数。





```
private int largestPoolSize;
private final BlockingQueue<Runnable>workQueue;
private volatile long keepAliveTime;
private volatile int corePoolSize;
private volatile int maximumPoolSize;
private volatile ThreadFactory threadFactory;
private volatile RejectedExecutionHandler handler;
```

上述数据成员对线程池的性能也有很大的影响，我会将它们放到构造中讲解。

```
privatefinal HashSet<Worker> workers= new HashSet<Worker>();
privatelong completedTaskCount;
private volatile boolean allowCoreThreadTimeOut;
private int largestPoolSize;
```



completedTaskCount表示线程池已完成的任务数。

allowCoreThreadTimeeOut表示是否允许核心线程在空闲状态下自行销毁。

largestPoolSize 表示线程池从创建到现在，池中线程的最大数量

```
private final HashSet<Worker> workers = new HashSet<Worker>();
```



workers是个HashSet容器，它存储的是Worker类的对象，Worker是线程池的内部类，它继承了Runnable接口，不严格的情况下，可以将一个Worker对象看成Thread对象，也就是工作的线程。shutdown和shutdownNow方法中会使用workers完成对所有线程的遍历。

```
privatefinal ReentrantLock mainLock =new ReentrantLock();
privatefinal Condition termination = mainLock.newCondition();
```

mainLock主要用于同步访问（或者说改变）线程池的状态以及线程池的各项参数，比如completedTaskCount和workers等。

在awaitTermination方法中，（mianLock的）termination是用于延时的条件队列。





# 2.构造函数

```
publicThreadPoolExecutor(int corePoolSize,
        int maximumPoolSize,
        long keepAliveTime,
        TimeUnit unit,
        BlockingQueue<Runnable> workQueue,
        ThreadFactory threadFactory,
        RejectedExecutionHandler handler)
```

线程池的构造函数参数多达7个，现在我们一一来分析它们对线程池的影响。

​    corePoolSize：线程池中核心线程数的最大值

​    maximumPoolSize：线程池中能拥有最多线程数

​    workQueue：用于缓存任务的阻塞队列

​    我们现在通过向线程池添加新的任务来说明着三者之间的关系。

   （1）如果没有空闲的线程执行该任务且当前运行的线程数少于corePoolSize，则添加新的线程执行该任务。

   （2）如果没有空闲的线程执行该任务且当前的线程数等于corePoolSize同时阻塞队列未满，则将任务入队列，而不添加新的线程。

   （3）如果没有空闲的线程执行该任务且阻塞队列已满同时池中的线程数小于maximumPoolSize，则创建新的线程执行任务。

   （4）如果没有空闲的线程执行该任务且阻塞队列已满同时池中的线程数等于maximumPoolSize，则根据构造函数中的handler指定的策略来拒绝新的任务。

​    注意，线程池并没有标记哪个线程是核心线程，哪个是非核心线程，线程池只关心核心线程的数量。

​    通俗解释，如果把线程池比作一个单位的话，corePoolSize就表示正式工，线程就可以表示一个员工。当我们向单位委派一项工作时，如果单位发现正式工还没招满，单位就会招个正式工来完成这项工作。随着我们向这个单位委派的工作增多，即使正式工全部满了，工作还是干不完，那么单位只能按照我们新委派的工作按先后顺序将它们找个地方搁置起来，这个地方就是workQueue，等正式工完成了手上的工作，就到这里来取新的任务。如果不巧，年末了，各个部门都向这个单位委派任务，导致workQueue已经没有空位置放新的任务，于是单位决定招点临时工吧（临时工：又是我！）。临时工也不是想招多少就找多少，上级部门通过这个单位的maximumPoolSize确定了你这个单位的人数的最大值，换句话说最多招maximumPoolSize–corePoolSize个临时工。当然，在线程池中，谁是正式工，谁是临时工是没有区别，完全同工同酬。

​    keepAliveTime：表示空闲线程的存活时间。

​    TimeUnitunit：表示keepAliveTime的单位。

​    为了解释keepAliveTime的作用，我们在上述情况下做一种假设。假设线程池这个单位已经招了些临时工，但新任务没有继续增加，所以随着每个员工忙完手头的工作，都来workQueue领取新的任务（看看这个单位的员工多自觉啊）。随着各个员工齐心协力，任务越来越少，员工数没变，那么就必定有闲着没事干的员工。这样的话领导不乐意啦，但是又不能轻易fire没事干的员工，因为随时可能有新任务来，于是领导想了个办法，设定了keepAliveTime，当空闲的员工在keepAliveTime这段时间还没有找到事情干，就被辞退啦，毕竟地主家也没有余粮啊！当然辞退到corePoolSize个员工时就不再辞退了，领导也不想当光杆司令啊！

​    handler：表示当workQueue已满，且池中的线程数达到maximumPoolSize时，线程池拒绝添加新任务时采取的策略。

为了解释handler的作用，我们在上述情况下做另一种假设。假设线程池这个单位招满临时工，但新任务依然继续增加，线程池从上到下，从里到外真心忙的不可开交，阻塞队列也满了，只好拒绝上级委派下来的任务。怎么拒绝是门艺术，handler一般可以采取以下四种取值。

| ThreadPoolExecutor.AbortPolicy()         | 抛出RejectedExecutionException异常             |
| ---------------------------------------- | ---------------------------------------------- |
| ThreadPoolExecutor.CallerRunsPolicy()    | 由向线程池提交任务的线程来执行该任务           |
| ThreadPoolExecutor.DiscardOldestPolicy() | 抛弃最旧的任务（最先提交而没有得到执行的任务） |
| ThreadPoolExecutor.DiscardPolicy()       | 抛弃当前的任务                                 |

   workQueue：它决定了缓存任务的排队策略。对于不同的应用场景我们可能会采取不同的排队策略，这就需要不同类型的阻塞队列，在线程池中常用的阻塞队列有以下2种：

  （1）SynchronousQueue<Runnable>：此队列中不缓存任何一个任务。向线程池提交任务时，如果没有空闲线程来运行任务，则入列操作会阻塞。当有线程来获取任务时，出列操作会唤醒执行入列操作的线程。从这个特性来看，SynchronousQueue是一个无界队列，因此当使用SynchronousQueue作为线程池的阻塞队列时，参数maximumPoolSizes没有任何作用。



**SynchronousQueue，这里我尝试的时候，不是一个无界队列，参数maximumPoolSizes是作用的。**



  （2）LinkedBlockingQueue<Runnable>：顾名思义是用链表实现的队列，可以是有界的，也可以是无界的，但在Executors中默认使用无界的。

**当LinkedBlockingQueue的长度是无限的，那么maximunPoolSize就没有作用了。**







#### 可选择的阻塞队列BlockingQueue详解

在重复一下新任务进入时线程池的执行策略：
如果运行的线程少于corePoolSize，则 Executor始终首选添加新的线程，而不进行排队。（如果当前运行的线程小于corePoolSize，则任务根本不会存入queue中，而是直接运行）
如果运行的线程大于等于 corePoolSize，则 Executor始终首选将请求加入队列，而不添加新的线程。
如果无法将请求加入队列，则创建新的线程，除非创建此线程超出 maximumPoolSize，在这种情况下，任务将被拒绝。
主要有3种类型的BlockingQueue：

**无界队列**

队列大小无限制，常用的为无界的LinkedBlockingQueue，使用该队列做为阻塞队列时要尤其当心，当任务耗时较长时可能会导致大量新任务在队列中堆积最终导致OOM。阅读代码发现，Executors.newFixedThreadPool 采用就是 LinkedBlockingQueue，而楼主踩到的就是这个坑，当QPS很高，发送数据很大，大量的任务被添加到这个无界LinkedBlockingQueue 中，导致cpu和内存飙升服务器挂掉。

**有界队列**

常用的有两类，一类是遵循FIFO原则的队列如ArrayBlockingQueue与有界的LinkedBlockingQueue，另一类是优先级队列如PriorityBlockingQueue。PriorityBlockingQueue中的优先级由任务的Comparator决定。
使用有界队列时队列大小需和线程池大小互相配合，线程池较小有界队列较大时可减少内存消耗，降低cpu使用率和上下文切换，但是可能会限制系统吞吐量。

在我们的修复方案中，选择的就是这个类型的队列，虽然会有部分任务被丢失，但是我们线上是排序日志搜集任务，所以对部分对丢失是可以容忍的。

**同步移交队列**

如果不希望任务在队列中等待而是希望将任务直接移交给工作线程，可使用SynchronousQueue作为等待队列。SynchronousQueue不是一个真正的队列，而是一种线程之间移交的机制。要将一个元素放入SynchronousQueue中，必须有另一个线程正在等待接收这个元素。只有在使用无界线程池或者有饱和策略时才建议使用该队列。











   threadFactory：指定创建线程的工厂

   实际上ThreadPoolExecutor类中还有很多重载的构造函数，下面这个构造函数在Executors中经常用到。

```
public ThreadPoolExecutor(int corePoolSize,
        int maximumPoolSize,
        long keepAliveTime,
        TimeUnit unit,
        BlockingQueue<Runnable> workQueue) {
    this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);
}
```

注意到上述的构造方法使用Executors中的defaultThreadFactory()线程工厂和ThreadPoolExecutor中的defaultHandler抛弃策略。

   使用defaultThreadFactory创建的线程同属于相同的线程组，具有同为Thread.NORM_PRIORITY的优先级，以及名为"pool-XXX-thread-"的线程名（XXX为创建线程时顺序序号），且创建的线程都是非守护进程。

   defaultHandler缺省抛弃策是ThreadPoolExecutor.AbortPolicy()。

   除了在创建线程池时指定上述参数的值外，还可在线程池创建以后通过如下方法进行设置。

```
public void allowCoreThreadTimeOut(boolean value)
public void setKeepAliveTime(long time,TimeUnit unit)
public void setMaximumPoolSize(int maximumPoolSize)
public void setCorePoolSize(int corePoolSize)
public void setThreadFactory(ThreadFactory threadFactory)
public void setRejectedExecutionHandler(RejectedExecutionHandler handler)
```



# 3. 其它有关涉及池中线程数量的相关方法

```
public void allowCoreThreadTimeOut(boolean value)
public int prestartAllCoreThreads()
```

默认情况下，当池中有空闲线程，且线程的数量大于corePoolSize时，空闲时间超过keepAliveTime的线程会自行销毁，池中仅仅会保留corePoolSize个线程。如果线程池中调用了allowCoreThreadTimeOut这个方法，则空闲时间超过keepAliveTime的线程全部都会自行销毁，而不必理会corePoolSize这个参数。

   如果池中的线程数量小于corePoolSize时，调用prestartAllCoreThreads方法，则无论是否有待执行的任务，线程池都会创建新的线程，直到池中线程数量达到corePoolSize。



# 4. Executors中的线程池的工厂方法

为了防止使用者错误搭配ThreadPoolExecutor构造函数的各个参数以及更加方便简洁的创建ThreadPoolExecutor对象，JavaSE中又定义了Executors类，Eexcutors类提供了创建常用配置线程池的方法。以下是Executors常用的三个创建线程池的源代码。

   从源码中可以看出，Executors间接的调用了重载的ThreadPoolExecutor构造函数，并帮助用户根据不同的应用场景，配置不同的参数。

简而言之 Executors 工厂方法Executors.newCachedThreadPool() 提供了无界线程池，可以进行自动线程回收；Executors.newFixedThreadPool(int) 提供了固定大小线程池，内部使用无界队列；Executors.newSingleThreadExecutor() 提供了单个后台线程。

#### newCachedThreadPool

```
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue<Runnable>());
}
```



在newCachedThreadPool中如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
SynchronousQueue的大小不是1，而是0。

SynchronousQueue总结：

1：是无界的，队列的size始终为0，每个put操作需要等待take操作，反之也是一样。

2：默认是非公平。

3：在线程池中使用SynchronousQueue队列时，线程池内部只调用 offer添加，所以在未消费元素时，始终添加不进去，只有消费了元素，创建了不指向元素的头结点，之后offer才能添加元素。







#### newFixedThreadPool

```
public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
 }
```

线程数量固定，使用无限大的队列。



#### newScheduledThreadPool

创建一个定长线程池，支持定时及周期性任务执行。

```text
public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
        return new ScheduledThreadPoolExecutor(corePoolSize);
}
```

在来看看ScheduledThreadPoolExecutor（）的构造函数

```text
 public ScheduledThreadPoolExecutor(int corePoolSize) {
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
              new DelayedWorkQueue());
    } 
```

ScheduledThreadPoolExecutor的父类即ThreadPoolExecutor，因此这里各参数含义和上面一样。值得关心的是DelayedWorkQueue这个阻塞对列，在上面没有介绍，它作为静态内部类就在ScheduledThreadPoolExecutor中进行了实现。简单的说，DelayedWorkQueue是一个无界队列，它能按一定的顺序对工作队列中的元素进行排列。





#### newSingleThreadExecutor

创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

```text
public static ScheduledExecutorService newSingleThreadScheduledExecutor() {
        return new DelegatedScheduledExecutorService
            (new ScheduledThreadPoolExecutor(1));
 } 
```

首先new了一个线程数目为 1 的ScheduledThreadPoolExecutor，再把该对象传入DelegatedScheduledExecutorService中，看看DelegatedScheduledExecutorService的实现代码：

```text
DelegatedScheduledExecutorService(ScheduledExecutorService executor) {
            super(executor);
            e = executor;
} 
```

在看看它的父类

```text
DelegatedExecutorService(ExecutorService executor) { 
           e = executor; 
} 
```

其实就是使用装饰模式增强了ScheduledExecutorService（1）的功能，不仅确保只有一个线程顺序执行任务，也保证线程意外终止后会重新创建一个线程继续执行任务。





**【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor的方式，这样 的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明： Executors 返回的线程池对象的弊端如下： 1） FixedThreadPool 和 SingleThreadPool : 允许的请求队列长度为 Integer.MAX_VALUE ，可能会堆积大量的请求，从而导致 OOM 。 2） CachedThreadPool 和 ScheduledThreadPool : 允许的创建线程数量为 Integer.MAX_VALUE ，可能会创建大量的线程，从而导致 OOM 。**







# 5. 任务的提交过程

submit方法源码

```
    public Future<?> submit(Runnable task) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<Void> ftask = newTaskFor(task, null);
        execute(ftask);
        return ftask;
    }

    /**
     * @throws RejectedExecutionException {@inheritDoc}
     * @throws NullPointerException       {@inheritDoc}
     */
    public <T> Future<T> submit(Runnable task, T result) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<T> ftask = newTaskFor(task, result);
        execute(ftask);
        return ftask;
    }

    /**
     * @throws RejectedExecutionException {@inheritDoc}
     * @throws NullPointerException       {@inheritDoc}
     */
    public <T> Future<T> submit(Callable<T> task) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<T> ftask = newTaskFor(task);
        execute(ftask);
        return ftask;
    }
```



submit的实现方法位于抽象类AbstractExecutorService中，而此时execute方法还未实现（而是在AbstractExecutorService的继承类ThreadPoolExecutor中实现）。submit有三种重载方法，这里我选取了两个常用的进行分析，可以看出无论哪个submit方法都最终调用了execute方法。



execute

```
public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();
        /*
         * Proceed in 3 steps:
         *
         * 1. If fewer than corePoolSize threads are running, try to
         * start a new thread with the given command as its first
         * task.  The call to addWorker atomically checks runState and
         * workerCount, and so prevents false alarms that would add
         * threads when it shouldn't, by returning false.
         *
         * 2. If a task can be successfully queued, then we still need
         * to double-check whether we should have added a thread
         * (because existing ones died since last checking) or that
         * the pool shut down since entry into this method. So we
         * recheck state and if necessary roll back the enqueuing if
         * stopped, or start a new thread if there are none.
         *
         * 3. If we cannot queue task, then we try to add a new
         * thread.  If it fails, we know we are shut down or saturated
         * and so reject the task.
         */
        int c = ctl.get();
        if (workerCountOf(c) < corePoolSize) {
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        if (isRunning(c) && workQueue.offer(command)) {
            int recheck = ctl.get();
            if (! isRunning(recheck) && remove(command))
                reject(command);
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        else if (!addWorker(command, false))
            reject(command);
    }
```



由于execute方法中多次调用addWorker，我们这里就简要介绍一下它，这个方法的主要作用就是创建一个线程来执行Runnnable对象。

```
private boolean addWorker(Runnable firstTask, boolean core);
```







参考文章：

1. https://blog.csdn.net/jubaoquan/article/details/79198780
2. https://zhuanlan.zhihu.com/p/32867181
3. https://blog.csdn.net/weixin_41509424/java/article/details/84063561